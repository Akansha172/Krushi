{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a759b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==3.1.0a0 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (3.1.0a0)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from googletrans==3.1.0a0) (0.13.3)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.5.30)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
      "\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11824a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from flask) (8.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from flask) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from click>=5.1->flask) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\akanksha\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "677e8677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import NLTK \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0718cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\AKANKSHA/nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d4a129e31d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# document processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0msentence_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mword_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mlemmer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\AKANKSHA/nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\AKANKSHA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "from googletrans import LANGUAGES\n",
    "from flask import Flask,render_template,url_for,redirect,request\n",
    "\n",
    "# read document\n",
    "f=open('EXCEL.csv','r',errors='ignore')\n",
    "raw_doc=f.read()\n",
    "raw_doc=raw_doc.lower()\n",
    "\n",
    "# document processing\n",
    "sentence_tokens=nltk.sent_tokenize(raw_doc)\n",
    "word_tokens=nltk.word_tokenize(raw_doc)\n",
    "lemmer=nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "  return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punc_dict=dict((ord(punct),None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))\n",
    "\n",
    "greet_inputs=('hello','hi','wassup','hello there?')\n",
    "greet_responses=('Hi','Hey there!','There There!?')\n",
    "def greet(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower in greet_inputs:\n",
    "      return random.choice(greet_responses)\n",
    "#Construct response\n",
    "def response(user_response):\n",
    "  robo1_response=''\n",
    "  TfidVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "  tfidf=TfidVec.fit_transform(sentence_tokens)\n",
    "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "  #print(vals)\n",
    "  idx=vals.argsort()[0][-2]\n",
    "  #print(idx)\n",
    "  flat=vals.flatten()\n",
    "  flat.sort()\n",
    "  req_tfidf=flat[-2]\n",
    "  if (req_tfidf==0):\n",
    "    robo1_response=robo1_response+\"I am sorry,I am unable to understand you!\"\n",
    "    return robo1_response\n",
    "  else:\n",
    "    robo1_response=robo1_response+sentence_tokens[idx]\n",
    "    #print(sentence_tokens[idx])\n",
    "    return robo1_response\n",
    "\n",
    "app=Flask(__name__)\n",
    "@app.route('/')\n",
    "def welcome():\n",
    "  return render_template('index.html')\n",
    "\n",
    "@app.route('/answer/<string:ans>/<string:q>')\n",
    "def func(ans,q):\n",
    "  print(ans)\n",
    "  print(q)\n",
    "  return render_template('index2.html',answ=ans,qe=q)\n",
    "\n",
    "@app.route('/submit',methods=['POST','GET'])\n",
    "def submit():\n",
    "  if request.method=='POST':\n",
    "    # question=request.form['textbox']\n",
    "    # print(question)\n",
    "    translator = Translator()\n",
    "    unknown_sentence = x\n",
    "    results = translator.detect(unknown_sentence)\n",
    "    translation = translator.translate(x, dest='en')\n",
    "    x=translation.text\n",
    "    flag=0\n",
    "    if(results.lang == 'mr'):\n",
    "      flag==1\n",
    "    elif(results.lang == 'hi'):\n",
    "      flag==2\n",
    "    elif(results.lang == 'en'):\n",
    "      flag==0\n",
    "    x=request.form['speechtotext']\n",
    "    print(x)\n",
    "    flag=True\n",
    "    output_var=0\n",
    "    user_response=x\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thank you' or user_response=='thanks'):\n",
    "            flag=False\n",
    "            output_var = 'BOT: You are welcome...'\n",
    "        else:\n",
    "            if(greet(user_response)!=None):\n",
    "                output_var = 'BOT: '+greet(user_response)\n",
    "            else:\n",
    "                sentence_tokens.append(user_response)\n",
    "                word_tokens=word_tokens + nltk.word_tokenize(user_response)\n",
    "                final_words=list(set(word_tokens))\n",
    "                #output_var = 'BOT :> ',end='   '\n",
    "                position=1\n",
    "                for i in response(user_response):\n",
    "                    position += 1\n",
    "                    if i == '>':\n",
    "                        break\n",
    "                temp= response(user_response)[position:]\n",
    "            \n",
    "                if(flag==1):\n",
    "                    translator = Translator()\n",
    "                    user_output = translator.translate(temp, dest='mr')\n",
    "                    output_var= user_output.text\n",
    "        \n",
    "                elif(flag==2):\n",
    "                    translator = Translator()\n",
    "                    user_output = translator.translate(temp, dest='hi')\n",
    "                    output_var= user_output.text\n",
    "        \n",
    "                elif(flag==0):\n",
    "                    output_var= temp\n",
    "                \n",
    "                sentence_tokens.remove(user_response)\n",
    "\n",
    "    else: \n",
    "        flag=False\n",
    "        output_var= 'BOT: Goodbye!'\n",
    "\n",
    "    print(output_var)\n",
    "    q=x\n",
    "  return redirect(url_for('func',ans=output_var,q=x))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39b0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
